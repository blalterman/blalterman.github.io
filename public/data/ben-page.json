{
  "heading": "About Ben",
  "tagline": "How I ask big questions and who I ask them with.",
  "sections": [
    {
      "title": "Research Vision",
      "slug": "research-vision",
      "icon": "Telescope",
      "excerpt": "I study the Sun and solar wind to discover what it means for a Sun to create a habitable zone and to power life on Earth.",
      "paragraphs": [
        "I study the Sun and solar wind, the stream of charged particles it continuously emits, on timescales from seconds to decades to discover what it means for a Sun to create a habitable zone and to power life on Earth. I blend deep curiosity, creativity, and discipline to ask novel questions that push us beyond the edge of our current understanding. This builds transformative insights that reshape how we live here and now.",
        "No single instrument or single person can accomplish this task alone. We need highly specialized instruments that can observe a range of phenomena over timescales that can exceed any single instrument's lifetime and one person's career. The questions we ask and the challenges we face demand that we work together to achieve our goals. Questions of this scale don't just require teams—they define how great teams must function.",
        "I build teams that meet this definition: collaborative systems where diverse expertise converges, rigorous methods compound, and individual limitations transform into collective strength. Through these teams, we drive profound discovery. I believe the future of science depends not on brilliant individuals working in isolation, but on brilliant systems that make breakthrough insights inevitable rather than accidental. This research expands not just what we know, but what becomes knowable—creating collaborative foundations that transform today's grand challenges into tomorrow's scientific breakthroughs."
      ],
      "published": true
    },
    {
      "title": "Team Ethos",
      "slug": "team-ethos",
      "icon": "Compass",
      "excerpt": "I build high-trust teams where questions are celebrated and ownership is real, creating the psychological safety necessary to ask big questions.",
      "paragraphs": [
        "I build high-trust teams where questions are celebrated and ownership is real, creating the psychological safety necessary to ask big questions and take the risks required to answer them. This requires a subtle combination of independence and interdependence. We must be able to work on our own while simultaneously leaning on and collaborating with each other. This combination gives us the freedom to be creative, effective, and impactful as we drive results and push the bounds of human knowledge. In such environments, conflict is inevitable. By taking an us-against-the-problem approach, we put the problem on the wall and argue evidence, not intention, so teams leverage conflict as a tool to push us all forward and build beyond our individual visions. This turns team culture into a performance system that drives achievement and delivery while simultaneously fostering safety, care, and overall well-being.",
        "Teams of this caliber require strong principles, values, and practices to succeed. Our values—psychological safety, ownership, care, and a balance of independence with interdependence—govern how we treat one another. My principles—integrity, transparency, empathy, curiosity, rigor, and gratitude—set our standards. Our practices translate both into concrete habits: we cross-check evidence across missions so insights cohere; we write plainly and explain choices; we archive code and methods with each result; each milestone has a directly responsible individual; weekly check-ins keep momentum; monthly \"unlock\" milestones ensure near-term wins open the larger architecture.",
        "Today, we are building a new understanding of how the solar wind's helium abundance varies with the solar cycle, providing deep and nuanced insight into how helium impacts the solar wind's birth. These results also redefine how we understand the solar cycle and forecast its effects by separating two previously coupled problems: timing and amplitude of the solar cycle. This result strengthens solar cycle forecasts, improving our ability to safeguard human life and technology on Earth and in space."
      ],
      "published": true
    },
    {
      "title": "Mentorship Philosophy",
      "slug": "mentorship-philosophy",
      "icon": "HeartHandshake",
      "excerpt": "I help mentees build intuition for meeting problems in alignment with their values, modeling integrity, perseverance, and accountability.",
      "paragraphs": [
        "We promise ourselves and our children that their future will be better than our own. We can't predict it, but we can prepare by building adaptive systems and training people to respond skillfully as realities change. This awareness grounds my mentorship philosophy.",
        "In practice, I help mentees build intuition for meeting problems in alignment with their values. I model integrity, perseverance, discipline, and accountability, grounded in self-awareness, self-care, and self-respect. I lead with conscious vulnerability—showing how I tackle challenges, not only outcomes. I create space to sit with experience, reflect on their approach, strategize about the future, and deliberately choose the next step. I connect mentees with resources and a network that sustains this work. I invite them to name and act from personal truth so their actions stay true to their commitments and grounded in their principles. Our standard is clear. Leave ready to lead your own work with integrity, care, and vision. When it fits, return as a collaborator.",
        "Lasting change rarely comes from a single grand gesture. It accrues through small, repeated choices that shape our day-to-day work and build a more just, responsive, and thoughtful world where each of us belongs. When we support one another in that growth, we craft the future we promised. That is how I mentor."
      ],
      "published": true
    },
    {
      "title": "Open Science",
      "slug": "open-science",
      "icon": "Share2",
      "excerpt": "I practice Open Science by developing and sharing computational tools, archiving methods with results, and contributing to the broader scientific software ecosystem.",
      "paragraphs": [
        "Open Science is both a practical necessity and an ethical commitment. My conclusions are only as trustworthy as the methods behind them. I design software and documentation so others can validate, extend, and teach with them. When methods are visible, validation becomes possible. This transparency transforms scientific authority from persuasion to demonstration. Trust is earned through verifiable reproducibility, not through credentials or reputation alone. If you can read my methods, you can rebuild my results. If you can rebuild my results, you can assess my conclusions independently. This principle grounds every technical choice I make: openness is not an afterthought added for compliance, but the foundation that makes rigorous science possible.",
        "I separate evolving tools from time-stamped research. Libraries grow and improve over time as understanding deepens and methods mature. Published results must remain reproducible indefinitely, frozen at a specific moment so others can verify what I claimed when I claimed it. This separation honors both needs: continuous improvement in computational tools alongside permanent reproducibility in published work. I automate verification through tests and documentation builds that run continuously. Broken examples fail immediately. Quality checking happens with every change, not periodically before publication. This discipline transforms reproducibility from an aspirational goal into a routine practice—effortless rather than heroic. When verification is automatic, I can focus effort on discovery rather than maintenance. The boring parts stay boring, and the science stays reproducible.",
        "Open science is collaborative science. When tools and methods flow freely between researchers, the community advances faster than any individual could alone. Early-career scientists gain practical skills by reading production code, not just idealized examples. Researchers across institutions build directly on shared work without reinventing solutions. This approach distributes expertise more equitably and accelerates the pace of discovery. When methods are open, science advances through shared understanding rather than isolated expertise. Trust becomes communal rather than individual. That is why I share openly: because discovery serves humanity best when knowledge flows freely."
      ],
      "published": true
    },
    {
      "title": "Generative AI",
      "slug": "generative-ai",
      "icon": "Wrench",
      "excerpt": "I approach generative AI as a powerful tool that requires deliberate choices, thoughtful application, and clear accountability in scientific research.",
      "paragraphs": [
        "Generative AI is a tool—powerful and versatile, but always an instrument under human direction and accountability. This framing is not semantic; it is ethical. When we treat AI as a tool rather than an autonomous agent, we maintain clear lines of responsibility: the person using the tool bears accountability for the outcomes it produces. I think best in dialogue. Speaking out loud or typing slows me enough to clarify vision, choose deliberately, and set specific goals. A conversation with a model sharpens requirements and helps me articulate what I need before delegating execution. I retain authorship and final review over every claim, figure, and line of code. The tool does not bear responsibility—I do.",
        "I place AI where it adds leverage: after intent and requirements are set; during documentation, refactoring, and clarity passes; and as a second set of eyes on completeness—never as a substitute for interpretation, architecture, or deriving requirements from physical models. I disclose assistance whenever AI materially shapes text or code, and I avoid confidential or export-controlled inputs. Because science must be reproducible, AI-assisted steps must be reproducible. I document what tools I used, how I applied them, and how I validated outputs. Generative work can be broad—scaffolds, refactors, features, data transformations—but lands in targetted, reviewable increments behind tests and code review. This discipline maintains scientific integrity while capturing AI's strengths.",
        "To make AI effective and safe, I engineer the system around it. Clean repository practices—tests, continuous integration, version control, and clear documentation—scaffold changes that are easy to review and reproduce. I work requirements-first and link each requirement to reviewable commits. Clear expectations keep reviews focused on artifacts and criteria, not people, building shared ownership and trust. This approach places responsibility where it belongs: on human judgment, team culture, and the practices we build together. When wielded deliberately and reviewed rigorously, AI serves discovery without compromising the integrity that makes science communal. To see these principles implemented in concrete infrastructure, explore my work on AI-Assisted Development, where I built SolarWindPy as an intentionally opinionated framework with 7 specialized validation agents that demonstrate how deliberate architecture makes AI collaboration safe and effective for research, production, and regulated software development."
      ],
      "published": true
    },
    {
      "title": "AI-Assisted Development",
      "slug": "ai-assisted-development",
      "icon": "ShieldCheck",
      "excerpt": "I build infrastructure that makes AI-generated code safe, reliable, and trustworthy for scientific applications.",
      "paragraphs": [
        "I don't architect prompts—I architect frameworks that naturally and inherently solve big problems. AI-assisted development for research, production, and regulated commercial software faces common challenges despite different contexts. Across these contexts, developers engage with AI through unstructured conversation: describe needs, receive code, fix problems, repeat. For software requiring sustained correctness over weeks or months, this pattern breaks down through three compounding problems. Attention drift: human focus shifts from architectural vision to reactive troubleshooting, consuming creative energy and creating code and scope bloat. Context fragmentation: conversation history becomes archaeology rather than actionable memory, forcing developers to reconstruct intent from code rather than executing against explicit requirements. Validation uncertainty: syntactically correct code might violate domain requirements that generic AI cannot recognize. Frameworks address these problems through deliberate design—not by rushing AI to write more code faster, but by orchestrating AI tools to handle detailed implementation while slowing the developer's pace to maintain architectural vision and creative oversight. The developer becomes conductor with discipline: offloading well-scoped, actionable tasks to AI while maintaining execution rigor through deliberate requirements definition, validation oversight, and architectural decision-making. The apparent paradox resolves: frameworks prevent rushed decision-making that creates expensive errors while accelerating delivery through effective AI collaboration. This deliberate pace creates safety—both scientific correctness and regulatory compliance—through verifiable development practices.",
        "I built SolarWindPy as an intentionally opinionated framework for space physics data analysis. This opinionated architecture naturally creates effective and transparent guardrails for AI collaboration—establishing explicit boundaries for creative collaboration. This transparency serves both scientific rigor and the kind of audit trail regulatory frameworks demand, demonstrating how deliberate architecture enables AI use in contexts requiring verified correctness. The approach operates through three integrated layers that enforce disciplined development while accelerating execution.\n\nSolarWindPy establishes enforceable boundaries through opinionated data structures. This structure reflects SolarWindPy's nested composition pattern: Vector and Tensor objects provide foundational measurements, which compose into Ion and MagneticField objects representing distinct plasma components, which together compose into the unified Plasma framework. This hierarchical architecture creates natural guardrails—each object scopes specific functionality to the correct abstraction level, preventing scope creep and namespace bloat. Ion objects require exactly six physical measurements—validated at instantiation so invalid plasma representations raise errors before reaching the codebase. The package architecture uses three-level MultiIndex columns, creating predictable patterns AI learns and replicates reliably across thirteen thousand lines of scientific computing code. These design decisions encode space physics requirements as structure that constrains both human and AI work within scientifically valid boundaries.\n\nAutomated validation runs through pre-commit hooks and continuous integration pipelines. In SolarWindPy, physics validation ensures SI units are maintained internally throughout calculations and enforces unit conversions for storage and display. Validation gates slow hasty commits while enabling rapid iteration within verified boundaries. The framework encodes correctness; the hooks enforce it systematically without human intervention.\n\nRequirements-first planning maintains continuity across development sessions and enforces disciplined workflow. GitHub Issues decompose comprehensive plans into explicit phases with dependencies and artifact preservation. This workflow keeps AI-executed tasks aligned with project objectives, preventing scope drift.\n\nThe result is a production package deployed to PyPI, conda-forge, and ReadTheDocs. Development velocity increased 9.2-fold compared to active traditional development—from 0.49 commits per day during pre-AI development (2019-2021) to 4.51 commits per day with AI infrastructure, sustaining over 11 commits per day during continuous active development periods. The infrastructure enabled deployment of the first stable PyPI release within 25 days of establishing AI workflows. Critically, 76.7% of commits are explicitly co-authored with Claude, demonstrating systematic AI integration rather than occasional usage—the complete validation infrastructure, including 7 specialized agents (strategically consolidated from 14 by replacing mechanical validation with automated hooks while retaining domain expertise), lives publicly in SolarWindPy's .claude/ directory with 1,561 lines of development documentation.",
        "This work demonstrates AI alignment principles in practice: making AI helpful through acceleration, harmless through validation, and honest through transparency. The infrastructure doesn't just prevent errors in SolarWindPy—it establishes patterns for making AI reliable in any domain where correctness matters deeply. When we architect frameworks that encode domain expertise as enforceable rules, we transform AI from a black box into an accountable tool operating within validated boundaries that teams and regulatory bodies can examine, audit, and reference. The framework approach preserves human agency—developers conduct architecture and requirements while AI accelerates mechanical implementation—enabling effective collaboration that serves work requiring verified correctness. This matters beyond scientific computing. Medical software development needs clinical validation frameworks, helping teams meet HIPAA and FDA compliance requirements through systematic correctness checking and audit trail preservation. Legal application development needs precedent verification structures supporting ethical practice standards and regulatory oversight. Engineering systems require safety compliance guardrails meeting industry-specific regulations through automated validation and documented decision-making. Financial applications demand regulatory rule enforcement with comprehensive audit trails demonstrating how code changes maintain compliance over time. Trust emerges from demonstrated reliability, not from claims of capability. Each domain requires its own specialized frameworks encoding relevant expertise, but the underlying pattern holds: encode domain knowledge as enforceable rules, automate validation that catches errors human review might miss under time pressure, maintain human authority over requirements and review, and separate human architectural judgment from AI mechanical execution. By building these frameworks now, we establish patterns for effective human-AI collaboration that serve work demanding sustained correctness across research, production, and regulated contexts. This isn't about limiting AI—it's about making AI safe enough to trust with work that matters."
      ],
      "published": true
    }
  ]
}
